{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "import pandas as pd\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Skill Extraction**\n",
    "\n",
    "### **Data Ingestion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the Datasets\n",
    "job_postings = pd.read_csv('../data/cleaned_job_postings.csv')\n",
    "job_skills = pd.read_csv('../data/cleaned_job_skills.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merge the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge left on job_postings and job_skills on the 'job_link' column\n",
    "merged_data = job_postings.merge(job_skills, on='job_link', how='left')\n",
    "\n",
    "# Drop the 'job_link' column\n",
    "merged_data = merged_data.drop(columns=['job_link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Split the job_skills column into a list of skills**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the job_skills column into a list of skills\n",
    "merged_data['job_skills'] = merged_data['job_skills'].str.split(', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explode the Job_Skills Column and Remove any Null or Empty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the Split job_skills\n",
    "skill_breakdown = merged_data.explode('job_skills')\n",
    "\n",
    "# Remove any Null or Empty Skills\n",
    "skill_breakdown = skill_breakdown.dropna(subset=['job_skills'])\n",
    "skill_breakdown = skill_breakdown[skill_breakdown['job_skills'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Standardize / Categorize Skills**\n",
    "\n",
    "#### **Method 1 - Direct Skill Standardization / Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to dynamically map skills based on keywords\n",
    "def dynamic_skill_mapping(skill):\n",
    "\n",
    "    # Standardizing Education-Related Skills\n",
    "\n",
    "    bachelor_variations = [\n",
    "        \"bachelor of\", \"bachelor's\", \"ba\", \"bs\", \"b.a.\", \"b.s.\",\n",
    "        \"bachelor\", \"bachlor\", \"bacs\", \"bsc\", \"b.sc.\"\n",
    "    ]\n",
    "    \n",
    "    master_variations = [\n",
    "        \"master of\", \"master's\", \"ma\", \"ms\", \"m.a.\", \"m.s.\",\n",
    "        \"master\", \"mphil\", \"m.phil.\", \"mpa\", \"m.p.a.\", \"msc\", \"m.sc.\"\n",
    "    ]\n",
    "    \n",
    "    phd_variations = [\n",
    "        \"phd\", \"doctorate\", \"doctor of philosophy\", \"doctor's degree\",\n",
    "        \"ph.d.\", \"phd.\", \"dr\", \"dr.\", \"doctor\"\n",
    "    ]\n",
    "\n",
    "    for variation in bachelor_variations:\n",
    "        if variation in skill:\n",
    "            return \"bachelor's degree\"\n",
    "    \n",
    "    for variation in master_variations:\n",
    "        if variation in skill:\n",
    "            return \"master's degree\"\n",
    "    \n",
    "    for variation in phd_variations:\n",
    "        if variation in skill:\n",
    "            return \"phd\"\n",
    "\n",
    "    # Grouping AWS Certifications into Categories\n",
    "    if \"aws cloud practitioner\" in skill:\n",
    "        return \"AWS Fundamentals\"\n",
    "    if \"developer\" in skill and \"aws\" in skill:\n",
    "        return \"AWS Developer Certifications\"\n",
    "    if \"architect\" in skill and \"aws\" in skill:\n",
    "        return \"AWS Architecture Certifications\"\n",
    "    if \"devops\" in skill and \"aws\" in skill:\n",
    "        return \"AWS DevOps Certifications\"\n",
    "    if \"sysops\" in skill and \"aws\" in skill:\n",
    "        return \"AWS SysOps Administrator\"\n",
    "    \n",
    "    # Standardizing Data Science & Machine Learning Skills\n",
    "    if \"machine learning\" in skill or \"ml engineer\" in skill:\n",
    "        return \"machine learning\"\n",
    "    if \"deep learning\" in skill:\n",
    "        return \"deep learning\"\n",
    "    if \"natural language processing\" in skill or \"nlp\" in skill:\n",
    "        return \"natural language processing\"\n",
    "\n",
    "    # Cloud & Infrastructure Skills\n",
    "    if \"gcp\" in skill or \"google cloud\" in skill:\n",
    "        return \"Google Cloud Platform\"\n",
    "    \n",
    "    # Business Intelligence & Data Analysis\n",
    "    if \"power bi\" in skill:\n",
    "        return \"Power BI\"\n",
    "    if \"tableau\" in skill:\n",
    "        return \"Tableau\"\n",
    "    if \"excel\" in skill or \"spreadsheet\" in skill:\n",
    "        return \"Excel\"\n",
    "    \n",
    "    # Programming Languages\n",
    "    if \"python\" in skill:\n",
    "        return \"Python\"\n",
    "    if \"r programming\" in skill or skill == \"r\":\n",
    "        return \"R Programming\"\n",
    "    if \"java\" in skill:\n",
    "        return \"Java\"\n",
    "    if \"javascript\" in skill or \"js\" in skill:\n",
    "        return \"JavaScript\"\n",
    "    if \"c++\" in skill or \"c plus plus\" in skill:\n",
    "        return \"C++\"\n",
    "\n",
    "    # Databases\n",
    "    if \"postgresql\" in skill or \"postgre\" in skill:\n",
    "        return \"PostgreSQL\"\n",
    "    if \"mongodb\" in skill:\n",
    "        return \"MongoDB\"\n",
    "    \n",
    "    if \"$\" in skill or \"hour\" in skill or \"day\" in skill:\n",
    "        return None\n",
    "    \n",
    "    if \"relevant\" in skill or \"related\" in skill:\n",
    "        return None\n",
    "\n",
    "    if \"24/7\" in skill or \"24x7\" in skill:\n",
    "        return None\n",
    "\n",
    "    if \"401k\" in skill or \"401(k)\" in skill or \"retirement\" in skill:\n",
    "        return None   \n",
    "    \n",
    "    if \"*\" in skill:\n",
    "        return skill[1:].strip()\n",
    "    \n",
    "    if \"'big data'\" in skill:\n",
    "        return \"big data\"\n",
    "    \n",
    "    if \"years experience\" in skill or \"years of experience\" in skill or \"years'\" in skill or \"year of\" in skill or \"year\" in skill:\n",
    "        return None\n",
    "    \n",
    "    if \"a/b\" in skill:\n",
    "        return \"a/b testing\"\n",
    "    \n",
    "    if \"ability\" in skill:\n",
    "        return None\n",
    "    \n",
    "    if \"bsa\" in skill:\n",
    "        return \"bsa/aml\"\n",
    "    \n",
    "    if \"data engineering\" in skill:\n",
    "        return \"data engineering\"\n",
    "    \n",
    "    if \"data entry\" in skill:\n",
    "        return \"data entry\"\n",
    "    \n",
    "    if \"etl\" in skill:\n",
    "        return \"ETL\"\n",
    "\n",
    "    # Default: Return skill as is if no match is found\n",
    "    return skill\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Execution and Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize job_skills to lowercase and remove extra spaces\n",
    "skill_breakdown[\"lowercase_skills\"] = skill_breakdown[\"job_skills\"].str.lower().str.strip()\n",
    "\n",
    "# Apply the dynamic skill mapping function to the unique skills list\n",
    "cleaned_unique_skills = [dynamic_skill_mapping(skill) for skill in skill_breakdown[\"lowercase_skills\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Row Count: 150000\n",
      "Skill Breakdown Row Count After Cleaning: 150000\n"
     ]
    }
   ],
   "source": [
    "# Row Count Check:\n",
    "print (f\"\"\"Original Row Count: {len(skill_breakdown)}\n",
    "Skill Breakdown Row Count After Cleaning: {len(cleaned_unique_skills)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the job_skills column with the cleaned skills\n",
    "skill_breakdown[\"job_skills\"] = cleaned_unique_skills\n",
    "\n",
    "# Drop the lowercase_skills column\n",
    "skill_breakdown = skill_breakdown.drop(columns=[\"lowercase_skills\"])\n",
    "\n",
    "# Drop Null or Empty Rows\n",
    "skill_breakdown = skill_breakdown.dropna(subset=['job_skills'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **MVP Categorically Common Skill Standardization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skill Normalization by Ranking Priority\n",
    "skill_normalization = {\n",
    "    \n",
    "    # Classification Control to limit clash of the multiple Skill Standardizations (Refer to Jose's Section)\n",
    "    \n",
    "    \"bachelor's degree\": r\"(?i)\\bbachelor's degree\\b\",\n",
    "    \"master's degree\": r\"(?i)\\bmaster's degree\\b\",\n",
    "    \"phd\": r\"(?i)\\bphd\\b\",\n",
    "    \"AWS Fundamentals\": r\"(?i)\\bAWS Fundamentals\\b\",\n",
    "    \"AWS Developer Certifications\": r\"(?i)\\bAWS Developer Certifications\\b\",\n",
    "    \"AWS Architecture Certifications\": r\"(?i)\\bAWS Architecture Certifications\\b\",\n",
    "    \"AWS DevOps Certifications\": r\"(?i)\\bAWS DevOps Certifications\\b\",\n",
    "    \"AWS SysOps Administrator\": r\"(?i)\\bAWS SysOps Administrator\\b\",\n",
    "    \n",
    "    # Cloud & Infrastructure Engineering:\n",
    "    \n",
    "    \"Troubleshooting\": r\"(?i)troubleshooting\",\n",
    "    \"Linux\": r\"(?i)linux\",\n",
    "    \"Communication\": r\"(?i)communication|communication\\s+skills|comm|comms|communicate\",\n",
    "    \"Cabling\": r\"(?i)cable[-\\s]*ing\",\n",
    "    \"Networking\": r\"(?i)networking\",\n",
    "    \"Data Center Operations\": r\"(?i)data\\s+center\\s+operations\",\n",
    "    \"Windows\": r\"(?i)windows\",\n",
    "    \"Azure Data Factory\": r\"(?i)azure\\s+data\\s+factory|azuredatafactory\",\n",
    "    \"Terraform\": r\"(?i)terraform\",\n",
    "    \"Bash\": r\"(?i)(bash|shell|command\\s+line|cli)\",\n",
    "    \"Big Data\": r\"(?i)big\\s+data|bigdata\",\n",
    "    \"Data Engineering\": r\"(?i)data\\s+engineering|dataeng|data\\sengg|data\\sengr\",\n",
    "    \"Databricks\": r\"(?i)databricks\",\n",
    "    \"Go\": r\"(?i)go|golang\",\n",
    "    \"Inventory Management\": r\"(?i)inventory\\s+management|inv\\s+mgmt|inv\\s+mgmnt\",\n",
    "    \n",
    "    # Data Analyst:\n",
    "    \n",
    "    \"Data Analysis\": r\"(?i)data\\s*(analysis|analytics)|data\\s*analyse\",\n",
    "    \"Tableau\": r\"(?i)tableau\",\n",
    "    \"Data Visualization\": r\"(?i)data\\s+visualization|data\\s+visualisation\",\n",
    "    \"Excel\": r\"(?i)excel\",\n",
    "    \"Power BI\": r\"(?i)power\\s*bi\",\n",
    "    \"Statistics\": r\"(?i)statistics|statistical\",\n",
    "    \"Reporting\": r\"(?i)reporting|reports\",\n",
    "    \"Teamwork\": r\"(?i)teamwork|collaboration|team-\\s*first\\s*mentality\",\n",
    "    \"Data Mining\": r\"(?i)data\\s+mining|mining\",\n",
    "    \"Problem Solving\": r\"(?i)problem\\s+solving|troubleshooting\",\n",
    "    \"Business Intelligence\": r\"(?i)business\\s*intelligence|bi\",\n",
    "    \"Project Management\": r\"(?i)project\\s*management\",\n",
    "    \"Data Management\": r\"(?i)data\\s+management\",\n",
    "    \n",
    "    # Data Architect:\n",
    "    \n",
    "    \"Data Architecture\": r\"(?i)data\\s*(architecture|architect)\",\n",
    "    \"Data Modeling\": r\"(?i)data\\s*modeling|data\\s*models|data\\s*design\",\n",
    "    \"Data Warehousing\": r\"(?i)data\\s*warehousing|data\\s*marts|dw\",\n",
    "    \"Data Governance\": r\"(?i)data\\s*governance|data\\s*policy|data\\s*compliance\",\n",
    "    \"Snowflake\": r\"(?i)snowflake\",\n",
    "    \"Data Integration\": r\"(?i)data\\s*integration|etl|extract\\s+transform\\s+load|data\\s*flow\",\n",
    "    \"Data Quality\": r\"(?i)data\\s*quality|dq\",\n",
    "    \"Hadoop\": r\"(?i)hadoop\",\n",
    "    \"Data Security\": r\"(?i)data\\s*security|data\\s*protection|cybersecurity\",\n",
    "    \"ETL\": r\"(?i)etl|extract\\s+transform\\s+load|data\\s*flow\",\n",
    "    \"NoSQL\": r\"(?i)nosql\",\n",
    "    \n",
    "    #Data Engineer:\n",
    "    \n",
    "    \"Spark\": r\"(?i)spark|apache\\s+spark\",\n",
    "    \"Scala\": r\"(?i)scala\",\n",
    "    \"Kafka\": r\"(?i)kafka|apache\\s+kafka\",\n",
    "    \"Redshift\": r\"(?i)redshift|amazon\\s+redshift\",\n",
    "    \"NoSQL\": r\"(?i)nosql\",\n",
    "    \"Hive\": r\"(?i)hive|apache\\s+hive\",\n",
    "    \"ETL\": r\"(?i)etl|extract\\s+transform\\s+load\",\n",
    "    \"MySQL\": r\"(?i)mysql\",\n",
    "    \"Agile\": r\"(?i)agile\",\n",
    "    \"EMR\": r\"(?i)emr|elastic\\s+mapreduce|amazon\\s+emr\",\n",
    "    \"Airflow\": r\"(?i)airflow|apache\\s+airflow\",\n",
    "    \"Cassandra\": r\"(?i)cassandra|apache\\s+cassandra\",\n",
    "    \n",
    "    # Data Governance & Security:\n",
    "    \n",
    "    \"Data Governance\": r\"(?i)data\\s*governance|dg\",\n",
    "    \"Data Privacy\": r\"(?i)data\\s+privacy\",\n",
    "    \"Analytical Skills\": r\"(?i)analytical\\s+skills\",\n",
    "    \"Computer Science\": r\"(?i)computer\\s+science|cs\",\n",
    "    \"Data Protection\": r\"(?i)data\\s+protection|data\\s*prot|dp\",\n",
    "    \"Data Stewardship\": r\"(?i)data\\s*stewardship\",\n",
    "    \"GIS\": r\"(?i)gis|geographic\\sinformation\\s+systems\",\n",
    "    \"GDPR\": r\"(?i)gdpr|general\\+data\\s+protection\\s+regulation\",\n",
    "    \n",
    "    # Data Modeling and Warehousing:\n",
    "    \n",
    "    \"JSON\": r\"(?i)json\",\n",
    "    \"SPARQL\": r\"(?i)sparql\",\n",
    "    \"AVRO\": r\"(?i)avro\",\n",
    "    \"Ontology\": r\"(?i)ontology\",\n",
    "    \"OpenAPI/YAML\": r\"(?i)openapi/yaml\",\n",
    "    \"OWL\": r\"(?i)owl\",\n",
    "    \"SKOS\": r\"(?i)skos\",\n",
    "    \"Data.World\": r\"(?i)data\\.world\",\n",
    "    \"RDFS\": r\"(?i)rdfs\",\n",
    "    \"Stardog\": r\"(?i)stardog\",\n",
    "    \"AnzoGraph\": r\"(?i)anzograph\",\n",
    "    \"Neptune\": r\"(?i)neptune\",\n",
    "    \"PoolParty\": r\"(?i)poolparty\",\n",
    "    \n",
    "    # Data Operations & management: engineering\n",
    "    \n",
    "    'Collaboration': r\"(?i)collaboration\",\n",
    "    'Attention to Detail': r\"(?i)attention\\s*to\\s*detail\",\\\n",
    "    'Microsoft Office Suite': r\"(?i)microsoft\\s*office(?:\\ssuite)?\",\n",
    "    'Data Validation': r\"(?i)data\\s*validation\",\n",
    "    \n",
    "    # Data Scientist:\n",
    "    \n",
    "    'Data Science': r\"(?i)data\\s*science\",\n",
    "    'Machine Learning': r\"(?i)machine\\s*learning|ml\",\n",
    "    'Mathematics': r\"(?i)mathematics|maths\",\n",
    "    'PyTorch': r\"(?i)pytorch\",\n",
    "    \n",
    "    # Data Specialist:\n",
    "    \n",
    "    'Data Entry': r\"(?i)data\\s*entry\",\n",
    "    'Multitasking': r\"(?i)multitasking\",\n",
    "    \n",
    "    # Data Engineer / Administrator:\n",
    "    \n",
    "    'Oracle': r\"(?i)oracle\",\n",
    "    'Database Administration': r\"(?i)database\\s*administration|db\\sa|dba\",\n",
    "    'SQL Server': r\"(?i)sql\\s*server\",\n",
    "    'PostgreSQL': r\"(?i)postgresql|postgres\",\n",
    "    'Database Design': r\"(?i)database\\sgesign|db\\sdesign|database\\sstructure\",\n",
    "    'PL/SQL': r\"(?i)pl/sql\",\n",
    "    'MongoDB': r\"(?i)(mongodb|mongo\\s*database)\",\n",
    "    'Performance Tuning': r\"(?i)performance\\stuning|tuning\",\n",
    "    \n",
    "    # ML Ops Engineer:\n",
    "    \n",
    "    'Reinforcement Learning': r\"(?i)reinforcement\\s*learning\",\n",
    "    'Probabilistic Graphs': r\"(?i)probabilistic\\s*graphs\",\n",
    "    'Flexibility': r\"(?i)flexibility\",\n",
    "    'NLP': r\"(?i)(nlp|natural\\s*language\\s*processing)\",\n",
    "    'Monitoring': r\"(?i)monitoring\",\n",
    "    'Autonomy': r\"(?i)autonomy\",\n",
    "    'Experimentation': r\"(?i)experimentation\",\n",
    "    'Deep Learning': r\"(?i)deep\\s*learning\",\n",
    "    'ML Ops': r\"(?i)(ml\\s*ops|mlops|machine\\s*learning\\s*operations)\",\n",
    "    'Workflow Orchestration': r\"(?i)workflow\\s*orchestration\",\n",
    "    'Product Ownership': r\"(?i)product\\s*ownership\",\n",
    "    \n",
    "    # Machine Learning Engineer:\n",
    "    \n",
    "    'TensorFlow': r\"(?i)(tensorflow|tensor\\s*flow)\",\n",
    "    'Pandas': r\"(?i)pandas\",\n",
    "    'Data Preparation': r\"(?i)data\\s*preparation\",\n",
    "    'Jupyter': r\"(?i)jupyter\",\n",
    "    'Numba': r\"(?i)numba\",\n",
    "    \"Cloud Computing\": r\"(?i)cloud\\s+computing|cc\",\n",
    "    'Model Deployment': r\"(?i)model\\s*deployment\",\n",
    "    \"Kubernetes\": r\"(?i)kubernetes|kube\",\n",
    "    'Docker': r\"(?i)docker\",\n",
    "    'Feature Engineering': r\"(?i)feature\\s*engineering\",\n",
    "    \n",
    "    # Risk and Compliance Analyst:\n",
    "    \n",
    "    'CISM': r\"(?i)(certified\\s*information\\s*systems\\s*manager|cism)\",\n",
    "    'JIRA': r\"(?i)jira\",\n",
    "    'CISSP': r\"(?i)(certified\\s*information\\s*systems\\s*security\\s*professional|cissp)\",\n",
    "    'CCSP': r\"(?i)(certified\\s*cloud\\s*security\\s*professional|ccsp)\",\n",
    "    'CISA': r\"(?i)(certified\\s*information\\s*systems\\s*auditor|cisa)\",\n",
    "    'Security+': r\"(?i)(comp\\.?\\s*tia\\ssecurity\\+\\s*certification|security\\+)\",\n",
    "    'GIAC': r\"(?i)giac\",\n",
    "    'AWS Cloud Practitioner': r\"(?i)(aws\\s*cloud\\s*practitioner|awscp)\",\n",
    "    'AWS Solution Architect Associate': r\"(?i)(aws\\s*solution\\s*architect\\s*associate|aws\\ssaa)\",\n",
    "    'AWS Solution Architect Professional': r\"(?i)(aws\\s*solution\\s*architect\\s*professional|aws\\sasap)\",\n",
    "    'AWS Developer Associate': r\"(?i)(aws\\s*developer\\s*associate|aws\\sdaa)\",\n",
    "    'AWS Security Specialty': r\"(?i)(aws\\s*security\\s*specialty|awsss)\",\n",
    "    'Virtualization': r\"(?i)virtualization\",\n",
    "    'Cybersecurity': r\"(?i)cybersecurity\",\n",
    "    'Data Loss Prevention (DLP)': r\"(?i)(data\\s*loss\\s*prevention|dlp)\",\n",
    "    'Network DLP': r\"(?i)(network\\s*dlp|ndlp)\",\n",
    "    'SaaS': r\"(?i)saas\",\n",
    "    \n",
    "    # Software and Platform Engineering:\n",
    "    \n",
    "    \"Software Engineering\": r\"(?i)software\\s+engineering\",\n",
    "    \"Kafka\": r\"(?i)kafka\",\n",
    "    \"C++\": r\"(?i)c\\+\\+|\\bCPLUSPLUS\\b\",\n",
    "    \"Algorithms\": r\"(?i)algorithms|algo\",\n",
    "    \"CI/CD\": r\"(?i)ci/cd|continuous\\s+integration/\\s*continuous\\s+deployment\",\n",
    "    \"AI\": r\"(?i)ai|artificial\\s+intelligence\",\n",
    "    \n",
    "    # General / Added:\n",
    "    \n",
    "    'Engineering': r\"(?i)engineering\",\n",
    "    'LLMs': r\"(?i)(llms|large\\s*language\\s*models)\",\n",
    "    \"Python\": r\"(?i)python(?:3(\\.\\d+)?)?|py\",\n",
    "    \"RDF\": r\"(?i)rdf\",\n",
    "    \"AWS\": r\"(?i)aws|amazon\\s+web\\sservices\",\n",
    "    \"SQL\": r\"(?i)sql\",\n",
    "    \"Azure\": r\"(?i)azure|microsft\\s+azure\",\n",
    "    \"Java\": r\"(?i)java|java\\s+ee|java\\s+se\",\n",
    "    \"R\": r\"(?i)(?:^|[\\s,])(r(?:\\s+(?:programming|language|studio|basics|core|developer|development|statistical|stats|analysis))?)\\b\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classification Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function To Standardize top 20 Skills by Job Classification\n",
    "def classify(skill):\n",
    "    for skill_name, keyword in skill_normalization.items():\n",
    "        if re.search(keyword, skill):\n",
    "            return skill_name\n",
    "    return skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Regex Function to skill_breakdown Dataframe\n",
    "skill_breakdown['job_skills'] = skill_breakdown['job_skills'].apply(classify)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implode skill_breakdown dataframe on Skills**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = skill_breakdown.groupby(['last_processed_time', 'job_title', 'company', 'City', 'State',\n",
    "                        'job_classification', 'job_keyword', 'seniority_level', 'seniority_level_keyword'], as_index=False).agg(\n",
    "    job_skills=('job_skills', list)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Convert and Output the Cleaned result_df as a JSON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the result_df into a JSON\n",
    "job_postings = json.loads(result_df.to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV has been converted to JSON successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save JSON to a file\n",
    "with open(\"../data/job_postings.json\", \"w\") as json_file:\n",
    "    json_file.write(json.dumps(job_postings, indent=4))\n",
    "print(\"CSV has been converted to JSON successfully!\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
