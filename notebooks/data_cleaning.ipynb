{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Cleaning**\n",
    "### **Data Ingestion**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "job_postings = pd.read_csv('../data/job_postings.csv')\n",
    "job_skills = pd.read_csv('../data/job_skills.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Removing Null or Missing Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate rows with null or missing values\n",
    "cleaned_job_postings = job_postings.dropna()\n",
    "cleaned_job_skills = job_skills.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Eliminating Unnecessary Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate unnecessary columns\n",
    "columns_to_drop = ['last_status', 'got_summary', 'got_ner', 'is_being_worked', 'first_seen', 'job_type', 'search_city', 'search_position', 'job_level', 'search_country']\n",
    "cleaned_job_postings = cleaned_job_postings.drop(columns=[col for col in columns_to_drop if col in cleaned_job_postings.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Removing Duplicate Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 752\n"
     ]
    }
   ],
   "source": [
    "# Eliminate duplicate rows\n",
    "columns_to_check = ['job_title', 'company', 'job_location']\n",
    "\n",
    "print(\"Number of duplicates:\", \n",
    "        cleaned_job_postings.duplicated(subset=columns_to_check).sum())\n",
    "\n",
    "cleaned_job_postings = cleaned_job_postings.drop_duplicates(subset=columns_to_check)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splitting the job_location Collumn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_job_postings[['City', 'State']] = cleaned_job_postings['job_location'].str.split(', ', n=1, expand = True)\n",
    "cleaned_job_postings = cleaned_job_postings.drop(columns='job_location')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Remove Non US Standardized Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of Valid US State Abbreviations\n",
    "valid_states = [\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
    "    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all Rows that dont have the Standardized US State Abbreviations\n",
    "cleaned_job_postings = cleaned_job_postings[cleaned_job_postings['State'].isin(valid_states)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Title Classification**\n",
    "### **Target Jobs Classification Regex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target job title regex list\n",
    "target_job_titles_regex = {\n",
    "    \"MLOps Engineer\": r\"(?i)(MLOps|Machine Learning Operations|Machine Learning Infrastructure Engineer|ML Infrastructure|ML Platform|ML Systems|ML Platform Engineer|AIML Ops Engineer|Machine Learning Software Developer)\\w*[-\\s]?\",\n",
    "\n",
    "    \"Machine Learning Engineer\": r\"(?i)(Machine Learning Engineer|ML Engineer|Machine Learning Engineering|ML Developer|Machine Learning Software Engineer|AIML Engineer|AIML Data Scientist|AI Data Science Lead)\\w*[-\\s]?\",\n",
    "\n",
    "    \"Data Architect\": r\"(?i)(Data Architect|Senior Data Architect|Cloud Data Architect|Big Data Architect|Enterprise Data Architect|Principal Data Architect|Lead Data Architect|Data Warehouse Architect|Data Architecture|Data Lake Architect|Data Streaming Architect)\\w*[-\\s]?\",\n",
    "\n",
    "    \"Database Engineer / Administrator\": r\"(?i)(Database|Database Architect|DBA\\b|Cloud Database|Azure Database|AWS Database|Databases|GCP Database|Oracle Database Engineer)\\w*[-\\s]?\",\n",
    "\n",
    "    \"Data Engineer\": r\"(?i)(Data Engineer|Senior Data Engineer|Lead Data Engineer|Big Data Engineer|Data Engineering|Data Engineering Manager|Data Engineering Architect|Data Pipeline Engineer|Big Data Developer|Data Engineers|Data Integrations|Data Infrastructure|ETL Developer)\\w*[-\\s]?\",\n",
    "\n",
    "    \"Data Governance & Security\": r\"(?i)(Data Governance|Data Privacy|Data Steward|Data Protection|Data Security|Master Data Management|Data Governance Manager|Data Compliance|Data Lifecycle Manager)\\w*[-\\s]?\",\n",
    "\n",
    "    \"Data Operations & Management\": r\"(?i)(Data Manager|Enterprise Data Manager|Data Operations|Data Operations Manager|Data Operations Analyst|Data Management Engineer|Data Strategy Manager|Data Solution Architect|Data Deployment|Data Conversion|Data Replication Engineer|DevOps Engineer|Distributed Systems|Storage)\\w*[-\\s]?\",\n",
    "\n",
    "    \"Data Modeling & Warehousing\": r\"(?i)(Data Modeling|Data Warehouse|Big Data Developer|Data Warehouse Architect|Cloud Datawarehouse|Data Platform Developer)\\w*[-\\s]?\",\n",
    "\n",
    "    \"Data Specialist\": r\"(?i)(Data Specialist|Data Processing|Data Consultant|Data Quality Manager|Data Coordinator|Data Entry Specialist)\\w*[-\\s]?\",\n",
    "\n",
    "    \"Data Scientist\": r\"(?i)(Data Scientist|Data Scientists|Data Science Engineer|Data Science Manager|Data Science Analyst|Data Science Practitioner|Customer Data Scientist)\\w*[-\\s]?\",\n",
    "\n",
    "    \"Data Analyst\": r\"(?i)(Data Analyst|Data Analysts|Financial Data Analyst|Business Intelligence|BI Analyst|Data Business Analyst|Data Insights Analyst)\\w*[-\\s]?\",\n",
    "\n",
    "    \"Software & Platform Engineering\": r\"(?i)(Software Engineer|Software Engineering|Software Developer|Software Engineer Data Science|Software Engineer Data Platforms|Platform Engineer|Application Developer|Backend Engineer|Systems Developer)\\w*[-\\s]?\",\n",
    "\n",
    "    \"Cloud & Infrastructure Engineering\": r\"(?i)(Cloud Data|Cloud Data Architect|Azure Data|AWS Data|Azure Databricks|AWS Databricks|Cloud Engineer|Cloud Platform Engineer|Infrastructure Engineer|Datacenter Technician|Datacenter Engineer|Datacenter Network Engineer|Datacenter Engineering|Site Reliability Engineer|SRE)\\w*[-\\s]?\",\n",
    "\n",
    "    \"Risk & Compliance Analytics\": r\"(?i)(Risk Analyst|AML\\b|BSA|Risk Modeling|Financial Analyst|Hedge Fund|Data Loss Prevention|DLP)\\w*[-\\s]?\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classification Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Classify Job Titles\n",
    "def classify(job_title, keywords_list=target_job_titles_regex):\n",
    "    for industry, keyword in keywords_list.items():\n",
    "        match = re.search(keyword, str(job_title))\n",
    "        if match:\n",
    "            keyword = re.sub(r'[^a-zA-Z\\s]', '', match.group()).strip().title()   # using match.group() to return the actual keyword that was matched rather than the regex pattern\n",
    "            return industry, keyword              \n",
    "    return \"unclassified\", \"unclassified\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Dataframe and Execute the classification function\n",
    "classified_job_titles = cleaned_job_postings.copy()\n",
    "classified_job_titles['job_classification'], classified_job_titles['job_keyword'] = zip(*classified_job_titles['job_title'].apply(classify))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Seniority Level Classification Regex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seniority level regex list\n",
    "seniority_levels_regex = {\n",
    "    # ðŸ”¹ Principal / Staff-Level Roles (Must Be Checked First)\n",
    "    \"Principal / Staff-Level\": r\"(?i)(Principal|Staff|Sr[-\\s]?Staff|Distinguished|Fellow|Master|L4|Level 4|Chief[-\\s]?Architect|Chief[-\\s]?Scientist)\\w*[-\\s]?\",\n",
    "\n",
    "    # ðŸ”¹ Lead / Supervisor Roles (Checked Before Senior)\n",
    "    \"Lead\": r\"(?i)(Lead|Tech[-\\s]?Lead|Team[-\\s]?Lead|Supervisor|Group[-\\s]?Lead|Project[-\\s]?Lead|Engineering[-\\s]?Lead|Squad[-\\s]?Lead|Chapter[-\\s]?Lead|Manager|Head[-\\s]?of[-\\s]?Team)\\w*[-\\s]?\",\n",
    "\n",
    "    # ðŸ”¹ Senior-Level Roles (Checked Before Mid-Level)\n",
    "    \"Senior-Level\": r\"(?i)(Senior|Sr\\.?|SNR|SEN|L3|Level 3|Expert|Specialist|Advanced|Seasoned|Experienced)\\w*[-\\s]?\",\n",
    "\n",
    "    # ðŸ”¹ Mid-Level Roles (Checked Before Junior)\n",
    "    \"Mid-Level\": r\"(?i)(Mid[-\\s]?Level|Intermediate|Mid|L2|Level 2|Professional|Regular)\\w*[-\\s]?\",\n",
    "\n",
    "    # ðŸ”¹ Entry-Level / Junior Roles (Checked After Principal & Senior)\n",
    "    \"Entry-Level / Junior\": r\"(?i)(Junior|Jr\\.?|Entry[-\\s]?Level|Associate|Graduate|Trainee|Fresher|New Grad|Early[-\\s]?Career|L1|Level 1)\\w*[-\\s]?\",\n",
    "\n",
    "    # ðŸ”¹ Intern / Internship Roles (Checked Last)\n",
    "    \"Intern\": r\"(?i)(Intern|Internship|Co[-\\s]?Op|Apprentice|Trainee)\\w*[-\\s]?\",\n",
    "\n",
    "    # ðŸ”¹ Director / Executive Roles (Checked Last for Highest Priority)\n",
    "    \"Director / Executive\": r\"(?i)(Director|Head|VP|Vice[-\\s]?President|CIO|CTO|CISO|CEO|Chief|Executive|C[-]?Level|Managing[-\\s]?Director|Global[-\\s]?Head|President|Founder|Partner)\\w*[-\\s]?\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Seniority Level Classification Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create single use function to classify seniority level\n",
    "def classify_seniority_level(job_title):\n",
    "    return classify(job_title, seniority_levels_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the classification function on the copied dataframe\n",
    "classified_job_titles['seniority_level'], classified_job_titles['seniority_level_keyword'] = zip(*classified_job_titles['job_title'].apply(classify_seniority_level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classify the Unclassified Seniority Titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a For Loop and If Conditional to classify the unclassified seniority titles\n",
    "for index, row in classified_job_titles.iterrows():\n",
    "    if row['seniority_level'] == 'unclassified':\n",
    "        if row['job_keyword'] == 'Data Analyst' or row['job_keyword'] == 'Data Security' or row['job_keyword'] == 'Database' or row['job_keyword'] == 'Cloud Engineer' or \\\n",
    "                row['job_keyword'] == 'Financial Data Analyst' or row['job_keyword'] == 'Bsa' or row['job_keyword'] == 'Machine Learning Engineer' or row['job_keyword'] == 'Data Processing' or \\\n",
    "                row['job_keyword'] == 'Backend Engineer' or row['job_keyword'] == 'Ml Engineering' or row['job_keyword'] == 'Data Governance' or row['job_keyword'] == 'Big Data Engineer' or \\\n",
    "                row['job_keyword'] == 'Aml' or row['job_keyword'] == 'Data Privacy' or row['job_keyword'] == 'Data Business Analyst' or row['job_keyword'] == 'Data Engineers' or \\\n",
    "                row['job_keyword'] == 'Data Engineer' or row['job_keyword'] == 'Infrastructure Engineer' or row['job_keyword'] == 'Datacenter Technician' or \\\n",
    "                row['job_keyword'] == 'Data Operations' or row['job_keyword'] == 'Data Science Engineer' or row['job_keyword'] == 'Data Consultant' or \\\n",
    "                row['job_keyword'] == 'Software Developer' or row['job_keyword'] == 'Data Science Analyst' or row['job_keyword'] == 'Bi Analyst' or \\\n",
    "                row['job_keyword'] == 'Ml Developer' or row['job_keyword'] == 'Ml Engineer' or row['job_keyword'] == 'Datacenter Engineer' or row['job_keyword'] == 'Platform Engineer' or \\\n",
    "                row['job_keyword'] == 'Cloud Data' or row['job_keyword'] == 'Etl Developer' or row['job_keyword'] == 'Dba' or row['job_keyword'] == 'Databases' or \\\n",
    "                row['job_keyword'] == 'Financial Analyst' or row['job_keyword'] == 'Devops Engineer' or row['job_keyword'] == 'Data Insights Analyst' or \\\n",
    "                row['job_keyword'] == 'Risk Analyst' or row['job_keyword'] == 'Data Analysts' or row['job_keyword'] == 'Cloud Database' or \\\n",
    "                row['job_keyword'] == 'Site Reliability Engineer' or row['job_keyword'] == 'Data Analystat' or row['job_keyword'] == 'Data Pipeline Engineer' or \\\n",
    "                row['job_keyword'] == 'Big Data Engineering':\t\n",
    "            classified_job_titles.loc[index, 'seniority_level'] = \"Entry-Level / Junior\" \n",
    "        elif row['job_keyword'] == 'Data Scientist' or row['job_keyword'] == 'Data Engineering' or row['job_keyword'] == 'MLOps Engineer' or \\\n",
    "                row['job_keyword'] == 'Business Intelligence' or row['job_keyword'] == 'Data Coordinator' or row['job_keyword'] == 'Data Steward' or \\\n",
    "                row['job_keyword'] == 'Machine Learning Infrastructure Engineer' or row['job_keyword'] == 'Machine Learning Software Developer' or row['job_keyword'] == 'Software Engineer' or \\\n",
    "                row['job_keyword'] == 'Customer Data Scientist' or row['job_keyword'] == 'Data Warehouse Architect'  or row['job_keyword'] == 'Ml Systems' or \\\n",
    "                row['job_keyword'] == 'Data Compliance' or row['job_keyword'] == 'Big Data Architect' or row['job_keyword'] == 'Aws Databricks' or \\\n",
    "                row['job_keyword'] == 'Big Data Developer' or row['job_keyword'] == 'Azure Data' or row['job_keyword'] == 'Data Replication Engineer' or \\\n",
    "                row['job_keyword'] == 'Data Science Practitioner' or row['job_keyword'] == 'Data Integrations' or row['job_keyword'] == 'Data Modeling' or \\\n",
    "                row['job_keyword'] == 'Machine Learning Operations' or row['job_keyword'] == 'Mlops' or row['job_keyword'] == 'Data Loss Prevention' or \\\n",
    "                row['job_keyword'] == 'Ml Infrastructure' or row['job_keyword'] == 'Machine Learning Software Engineer' or row['job_keyword'] == 'Data Deployment' or \\\n",
    "                row['job_keyword'] == 'Data Architecture' or row['job_keyword'] == 'Datacenter Network Engineer' or row['job_keyword'] == 'Azure Databricks' or \\\n",
    "                row['job_keyword'] == 'Data Stewardship' or row['job_keyword'] == 'Ml Platform' or row['job_keyword'] == 'Data Conversion' or \\\n",
    "                row['job_keyword'] == 'Data Management Engineer':\n",
    "            classified_job_titles.loc[index, 'seniority_level'] = \"Mid-Level\"\n",
    "        elif row['job_keyword'] == 'Data Architect' or row['job_keyword'] == 'Data Warehouse' or row['job_keyword'] == 'Cloud Data Architect' or \\\n",
    "                row['job_keyword'] == 'Data Protection' or row['job_keyword'] == 'Data Lake Architect' or row['job_keyword'] == 'Enterprise Data Architect' or \\\n",
    "                row['job_keyword'] == 'Data Solution Architect' or row['job_keyword'] == 'Data Streaming Architect':\n",
    "            classified_job_titles.loc[index, 'seniority_level'] = \"Senior-Level\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Drop unclassified rows**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows\n",
    "classified_job_titles = classified_job_titles[classified_job_titles['job_classification'] != 'unclassified']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Assign unique job_id to each job posting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a unique identifier to each job posting\n",
    "classified_job_titles['job_id'] = classified_job_titles.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add column name to the unique identifier\n",
    "classified_job_titles['job_id'] = 'job_' + classified_job_titles['job_id'].astype(str)\n",
    "\n",
    "#Make the job_id the first column\n",
    "classified_job_titles = classified_job_titles.set_index('job_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OUTPUT Cleaned CSVs** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files successfully exported to data directory\n"
     ]
    }
   ],
   "source": [
    "# Output cleaned job postings data\n",
    "classified_job_titles.to_csv('../data/cleaned_job_postings.csv', index=False)\n",
    "\n",
    "# Output cleaned job skills data \n",
    "job_skills.to_csv('../data/cleaned_job_skills.csv', index=False)\n",
    "\n",
    "print(\"CSV files successfully exported to data directory\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
